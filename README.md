# ğŸŒªï¸ Disaster Tweets Classification

A machine learning project that classifies tweets as disaster-related or not using RNN models. Built with Python, TensorFlow, and FastAPI.

## ğŸ“‹ Overview

This project uses natural language processing and deep learning to identify disaster-related tweets. The system analyzes text content and predicts whether a tweet is about a disaster or not.

## âœ¨ Features

- **Data Analysis & Preprocessing**: Text cleaning using NLTK
- **Multiple Embedding Methods**: GloVe, FastText, and custom embeddings
- **RNN Models**: LSTM/GRU-based neural networks
- **REST API**: FastAPI service for predictions
- **Docker Support**: Easy deployment

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                    # FastAPI application
â”‚   â”œâ”€â”€â”€â”€ api/                    # API endpoints
â”‚   â”œâ”€â”€â”€â”€ core/                   # Configuration
â”‚   â”œâ”€â”€â”€â”€ services/               # classificationa and text preprocessing logic
â”‚   â”œâ”€â”€â”€â”€ schemas/                # response and request classes
â”‚   â”œâ”€â”€â”€â”€ main.py                 # Entry point
â”‚   â”œâ”€â”€ data/                   # Dataset files
â”‚   â”œâ”€â”€ notebooks/              # Jupyter notebook
â”‚   â”‚   â””â”€â”€ notebook.ipynb      # Data analysis and model training
â”‚   â”œâ”€â”€ artifacts/              # Trained models
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Local Installation

1. **Clone and setup**
   ```bash
   git clone <repo-url>
   cd disaster-tweets-classification
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment**
   ```bash
   cp .env.example .env
   # Edit .env with your settings
   ```

4. **Run the API**
   ```bash
   uvicorn app:main --reload
   ```

### Docker Deployment

```bash
# Build and run
docker build -t disaster-classifier .
docker run -p 8000:8000 disaster-classifier
```

## ğŸ“¡ API Usage

### Classify Texts

**POST** `/predict`

```json
{
  "texts": ["Earthquake hits the city!", "Having lunch with friends"]
}
```

**Response:**
```json
{
  "predictions": [
    {
      "text": "Earthquake hits the city!",
      "predicted_label": "disaster",
      "probability": 0.89
    },
    {
      "text": "Having lunch with friends",
      "predicted_label": "non-disaster",
      "probability": 0.92
    }
  ]
}
```

## ğŸ§  Models

The project includes three different approaches:

1. **GloVe Embeddings**: Pre-trained word vectors + LSTM
2. **FastText Embeddings**: Facebook's FastText vectors + GRU  
3. **Custom Embeddings**: Trainable embedding layer + LSTM


## ğŸ”§ Configuration

Edit `.env` file:

```bash
APP_NAME="Text-Classification"
VERSION="1.0.0"
API_SECRET_KEY="" <-- add your api key here
```

## ğŸ“ Development

### Training Models

Open `src/notebooks/analysis.ipynb` to:
- Explore the dataset
- Preprocess text data
- Train different models
- Evaluate performance


## ğŸ› ï¸ Tech Stack

- **Python 3.12**
- **TensorFlow/Keras** - Deep learning
- **FastAPI** - Web framework
- **NLTK** - Text preprocessing
- **spaCy** - NLP tools
- **Docker** - Containerization

## ğŸ“ Contact

For questions or suggestions, please open an issue or contact [diaa.kotb42@gmail.com](mailto:diaa.kotb42@gmail.com).

---

â­ If this project helps you, please give it a star!